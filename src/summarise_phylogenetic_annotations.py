import subprocess
from usher_genotyping.src.logger import log
import os
import argparse
from typing import Optional
from typing import Sequence
import pandas
import glob
import numpy

"""
Review Annotation outputs
1. Read in original clade assignments # Done
2. Check Sample assignments to tree, and quality of assignment
3. Check Clade assignment and quality of additional samples
4. Identify samples that have changed assignment
4. Summarise Clade assignments of samples, whether they have changed

"""
def import_original_clade_assignments(original_clade_tsv):
    '''
    Import original genotypes and samples from tsv (which has no header) as a pandas df
    :params: tsv file [genotype\tsample_id]
    :return: pandas dataframe 
    '''
    # read in tsv file, add headers 
    if not os.path.isfile(original_clade_tsv):
        log('critical', f"======= Expected input file {original_clade_tsv} was not found. Please check and try again.")
        exit()
    else:
        orig_clade_df = pandas.read_csv(original_clade_tsv, names=["original_clade","sample_id"], sep='\t')
        return orig_clade_df

def check_file_is_present(file_path, file_name):
    #TODO: this isn't working as expected.
    '''
    Check if a file is present, if not log 
    :params: filepath, filename
    :return: log input
    '''
    if not os.path.isfile(file_path):
        log('critical', 
            f"======= Expected file {file_name} was not found at file path: {file_path}.\n\t======= Please check expected output files were generated.")
    else:
        log('info', f"======= Expected file {file_name} found.")
        return
    
def import_matutils_summary_data(summary_stats_folder):
    '''
    Import the datasets generated by matUtiles parsing of the ProtoBuf tree file
    :params: folder containing summary files
    :return: dataframes 
    '''

    # dataframe containing assigned clades
    sample_clades_tsv = os.path.join(summary_stats_folder, 'sample_clades.tsv')
    check_file_is_present(sample_clades_tsv, "sample_clades_tsv")
    sample_clades_df = pandas.read_csv(sample_clades_tsv, sep='\t', header=0, names=['sample_id','estimated_clade'])

    # parsimonious_placements
    parsimonious_placements_tsv = os.path.join(summary_stats_folder, 'equally_parsimonious_placements.tsv')
    check_file_is_present(parsimonious_placements_tsv, "equally_parsimonious_placements.tsv")
    parsimonious_placements_df = pandas.read_csv(parsimonious_placements_tsv, sep='\t', header=0, names=['sample_id','equally_parsimonious_placements', 'neighborhood_size'])
    
    # Clades summary df
    clades_summary_tsv = os.path.join(summary_stats_folder, 'clades.tsv')
    check_file_is_present(clades_summary_tsv, "clades_summary_tsv")
    clades_summary_df = pandas.read_csv(clades_summary_tsv, sep='\t')

    return sample_clades_df, parsimonious_placements_df, clades_summary_df


def inferring_iqr_analysis(df, column_name):
    '''
    Using a pandataframe and a column of numerical values calculate summary statistics using IQR
    :params: pandas dataframe, string for column name containing only numerical data
    :return: pandas df summarising the distribution of counts for the IQR
    '''
    # Make sure dataframe isn't empty
    if df.empty:
        log("cricital", f"====== Dataframe empty, cannot estimate IQR")
        return
    # Make sure column name is in dataframe
    if column_name not in df.columns:
        log("cricital", f"====== Column name {column_name} not found in dataframe.")
        return

    # Set up basic structure of dictionary to populate
    all_samples = df.shape[0]
    min_value = df[column_name].min()
    median_value = df[column_name].median()
    max_value = df[column_name].max()

    ipp_score_iqr = df[column_name].quantile([0.25, 0.75])
    lower_quantile = ipp_score_iqr[0.25]
    upper_quantile = ipp_score_iqr[0.75]

    names = [
        str("Total Samples"),
        str("Min. Value"),
        str("Median Value"),
        str("Max. Value"),
        str("≤")+str(lower_quantile), 
        str(lower_quantile)+str(" >")+str(" - ")+str("≤ ")+str(upper_quantile), 
        str("> ")+str(upper_quantile)]    

    sample_counts_list = [all_samples, min_value, median_value, max_value, "NA", "NA", "NA"]

     # Calculate Inter-quantile range for parismonious placement score for inperfect samples            
    if df[column_name].max() != df[column_name].min():
        sample_counts_list[4] = df[df[column_name] <= lower_quantile ].shape[0]
        sample_counts_list[6] = df[df[column_name] > upper_quantile ].shape[0]

        # if quantile range is not the same value calculate samples in the inter quantile range:
        if lower_quantile != upper_quantile:
            iqr_df = df[(df[column_name] >= lower_quantile) & (df[column_name] < upper_quantile)]
            sample_counts_list[5] = iqr_df.shape[0]
            iqr_dict = {"Summary": names, "Sample_counts": sample_counts_list }

        else:
            iqr_dict = {"Summary": names, "Sample_counts": sample_counts_list }

    # convert to pandas dataframe
    iqr_df = pandas.DataFrame(iqr_dict)

    # create list with IQR values
    iqr_values = [lower_quantile, upper_quantile]

    # Return dataframe
    return pandas.DataFrame(iqr_dict), iqr_values

def parsimonious_placements_review(parsimonious_placements_df):
    '''
    Summarise the phylogenetic tree using the parsimonious placements dataframe:
        - calculate the quantile ranges for parsiomony scores
        - Annotate samples with score of 1
        - annotate the number of samples in each quartile range
    :params: parsiomony df [sample (str), equally_parsimonious_placements (int), neighborhood_size (int)]
    :return: summary dataframe
    '''

    # Separate samples with perfect placement from the rest
    perfect_parsimonious_placements = parsimonious_placements_df[parsimonious_placements_df['equally_parsimonious_placements'] == int(1)]
    inperfect_parsimonious_placements = parsimonious_placements_df[parsimonious_placements_df['equally_parsimonious_placements'] > int(1)]

    # Calculate summary stats for imperfect placements
    pp_iqr_df, pp_iqr_values = inferring_iqr_analysis(inperfect_parsimonious_placements, str('equally_parsimonious_placements'))
    
    # Restructure and rename Pandas dataframe
    pp_iqr_df = pp_iqr_df.rename(columns={'Summary': 'Parsimonious_placement_score'})
    pp_iqr_df['Parsimonious_placement_score'] = pp_iqr_df['Parsimonious_placement_score'].replace({'Total Samples': 'PP > 1'})

    pp_iqr_df.loc[-2] = ['PP = 1', perfect_parsimonious_placements.shape[0]] # add row for perfect placements to top of the dataframe
    pp_iqr_df.index = pp_iqr_df.index + 2  # shifting index
    pp_iqr_df.sort_index(inplace=True)

    # Return a list of samples with parsimonious placements >1
    return pp_iqr_df, pp_iqr_values

def neighbourhood_size_review(parsimonious_placements_df):
    ''''
    Summarise phylogenetic tree using the neighbourhood size scores
    Neighbourhood size: longest direct traversable path between any two equally parsimonious placement locations for a given sample.
    :params: parsimony dataframe: [sample (str), equally_parsimonious_placements (int), neighborhood_size (int)]
    :return: summary dataframe
    
    '''
    # Separate samples with perfect placement from the rest
    perfect_neighbourhood_size = parsimonious_placements_df[parsimonious_placements_df['neighborhood_size'] == int(0)]
    inperfect_neighbourhood_size = parsimonious_placements_df[parsimonious_placements_df['neighborhood_size'] > int(0)]

    # infer inter quartile range for neighbourhood scores
    ns_iqr_df, ns_iqr_values = inferring_iqr_analysis(inperfect_neighbourhood_size, str('neighborhood_size'))
    # Rename columns/rows
    ns_iqr_df = ns_iqr_df.rename(columns={'Summary': 'neighborhood_size'})
    ns_iqr_df['neighborhood_size'] = ns_iqr_df['neighborhood_size'].replace({'Total Samples': 'NS > 1'})

    ns_iqr_df.loc[-2] = ['NS = 0', perfect_neighbourhood_size.shape[0]] # add row for perfect placements to top of the dataframe
    ns_iqr_df.index = ns_iqr_df.index + 2  # shifting index
    ns_iqr_df.sort_index(inplace=True)

    return ns_iqr_df, ns_iqr_values

def grouping_samples_phylo_assignment_scores(parsimonious_placements_df, pp_iqr_values, ns_iqr_values):
    '''
    - Group samples based on:
        1. EPP = 0 & NSS = 0 > 
        2. EPP = low & NSS = low > 
        3. EPPS = high & NSS = low > 
        4. EPPS = low & NSS = high > 
        5. EPPS = high & NSS = high
    - Annotate samples with appropriate group
    - Identify Good smaples
    :params: sample dataframe with scores
    :return; sample dataframe with scores and quality groups annotated to it
    '''
    conditions = [
    (parsimonious_placements_df['equally_parsimonious_placements'] == 1) & (parsimonious_placements_df['neighborhood_size'] == 0),
    (parsimonious_placements_df['equally_parsimonious_placements'] <= pp_iqr_values[0]) & (parsimonious_placements_df['neighborhood_size'] <= ns_iqr_values[0]),
    (parsimonious_placements_df['equally_parsimonious_placements'] > pp_iqr_values[0]) & (parsimonious_placements_df['neighborhood_size'] <= ns_iqr_values[0]),
    (parsimonious_placements_df['equally_parsimonious_placements'] <= pp_iqr_values[0]) & (parsimonious_placements_df['neighborhood_size'] > ns_iqr_values[0]),
    (parsimonious_placements_df['equally_parsimonious_placements'] > pp_iqr_values[0]) & (parsimonious_placements_df['neighborhood_size'] > ns_iqr_values[0]),
    ]

    choices = [
        str('PPS=1')+str(', NS=0'),
        str('PPS<=')+str(pp_iqr_values[0])+str(', NS<=')+str(ns_iqr_values[0]),
        str('PPS>')+str(pp_iqr_values[0])+str(', NS<=')+str(ns_iqr_values[0]),
        str('PPS<=')+str(pp_iqr_values[0])+str(', NS>')+str(ns_iqr_values[0]),
        str('PPS>')+str(pp_iqr_values[1])+str(', NS>')+str(ns_iqr_values[1])]

    parsimonious_placements_df['quality_group'] = numpy.select(conditions, choices)

    return parsimonious_placements_df

def add_inferred_sample_clades(summary_df, clades_summary_df, orig_clade_df):
    '''
    Add two columns to summary df, infferred clades and original clade assignments
    :params: dataframes for 
        summary table: ['sample_id', 'equally_parsimonious_placements', 'neighborhood_size', 'quality_group']
        inferred clades: ['sample_id', 'estimated_clade'], dtype='object']
        original clade assignments: ['original_clade', 'sample_id']
    retrun: summary_df with two additional columns
    '''
    # left join original clade assignments to summary df
    summary_df_merge = summary_df.merge(orig_clade_df, on='sample_id', how='left')
    # left join summary table and inferred clades
    summary_df_merge = summary_df_merge.merge(clades_summary_df, on='sample_id', how='left')
    
    return summary_df_merge

def summarise_clade_assignments(summary_df_merge):
    '''
    Compare the columns original_clade and estimated_clade for similarities, new assignment, changed assignment, no assignment
    :params: summary_df 
    :return: summary_df with clade assignment summary
    '''
    conditions = [
        (pandas.isnull(summary_df_merge['original_clade'])) & (pandas.isnull(summary_df_merge['estimated_clade'])), # No clades assigned
        (pandas.isnull(summary_df_merge['original_clade'])) & (pandas.isnull(summary_df_merge['estimated_clade']) == False), # Only original Clade assigned
        (pandas.isnull(summary_df_merge['estimated_clade'])) & (pandas.isnull(summary_df_merge['original_clade']) == False), # Only Estimated Clade assigned
        (summary_df_merge['original_clade'] == summary_df_merge['estimated_clade']), # Clade assignments are the same
        (summary_df_merge['original_clade'] != summary_df_merge['estimated_clade']) # Clade assignment has changed
        ]
    choices = [
        str('No Assignment'),
        str('Inferred clade only'),
        str('Original clade only'),
        str('Matched clade assignment'),
        str('Changed clade assignment')
        ]

    summary_df_merge['clade_assignment_summary'] = numpy.select(conditions, choices)
    return summary_df_merge

def write_to_csv(df, file_name):
    '''
    Write Pandas dataframe to csv
    :params: pandas dataframe object, str(file path/name)
    :return: N/A
    '''
    df.to_csv(file_name, index=False, sep=',')

def main(argv: Optional[Sequence[str]] = None) -> int:
    '''
    Main function for running script directly
    '''
    setup_logger()
    parser = argparse.ArgumentParser()
    parser.add_argument('--assigned_clades', '-c', required=True, help='Original clade assignment tsv file.')
    parser.add_argument('--summary_stats_folder', '-s', required=True, help='Summary stats folder generated by matUtils summary (Containing the sample_clades.tsv file)')
    parser.add_argument('--output', '-o', required=True, help='Output folder to save summary data')
    args = parser.parse_args(argv)

    # Read in files
    log('info', f"======= importing original clade assignment table")
    assigned_clade_df = import_original_clade_assignments(args.assigned_clades)
    log('info', f"======= Processessing files in summary stats folder: {args.summary_stats_folder}")
    sample_clades_df, parsimonious_placements_df, clades_summary_df = import_matutils_summary_data(args.summary_stats_folder)

    # Review sample placements in phylogenetic tree via parsimonious information
    log('info', f"======= Calculating parsimonious placements information.")
    pp_iqr_df, pp_iqr_values = parsimonious_placements_review(parsimonious_placements_df)

    # Review sample placements in phylogenetic tree via neighbourhood information
    log('info', f"======= Processessing neighbourhood size information.")
    ns_iqr_df, ns_iqr_values = neighbourhood_size_review(parsimonious_placements_df)

    # Annotate quality groups to samples
    log('info', f"======= Grouping samples by parsimonious placement and neighbourhood scores.")
    summary_df = grouping_samples_phylo_assignment_scores(parsimonious_placements_df, pp_iqr_values, ns_iqr_values)

    # Add inferred and annotated sample clades to final table
    log('info', f"======= Reviewing inferred sample clades")
    summary_df_merge = add_inferred_sample_clades(summary_df, sample_clades_df, assigned_clade_df)

    # Annotate summary of inferred vs assigned clades
    log('info', f"======= Summarising clade assignments")
    summary_df_merge_annotated = summarise_clade_assignments(summary_df_merge)

    # # Write to file
    output_filename = os.path.join(args.output, str('annotated_summary_stats.csv'))
    log('info', f"======= Writing summary data to output file: {output_filename}")
    write_to_csv(summary_df_merge_annotated, output_filename)

if __name__ == "__main__":
    exit(main())